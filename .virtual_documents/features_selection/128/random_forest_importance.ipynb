


%store -r X
%store -r y
%store -r X_test
%store -r y_test
%store -r feature_names


# Import thư viện
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier


from sklearn.model_selection import train_test_split
# Chia dữ liệu thành training set và validation set
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Kiểm tra kích thước của các tập dữ liệu
print("Kích thước của tập huấn luyện:", X_train.shape, y_train.shape)
print("Kích thước của tập xác thực:", X_val.shape, y_val.shape)


import matplotlib.pyplot as plt

# Reshape data
# Data ban đầu X(13166, 20, 128), y(13166)

# Reshape X về dạng 2d => X_2d(263320, 128), giữ nguyên 128 và đó là các đặc trưng
X_2d = X_train.reshape(-1, X.shape[-1])
# Reshape y thành y_reshaped(263320) bằng cách lặp mỗi phần tử trong y 20 lần
y_reshaped = np.repeat(y_train, 20)


# Khởi tạo mô hình Random Forest
model = RandomForestClassifier(n_estimators=500)
# Nó chỉ định số lượng cây quyết định sẽ được xây dựng và kết hợp để tạo thành khu rừng ngẫu nhiên trong thuật toán random forest.


# Huấn luyện mô hình
model.fit(X_2d, y_reshaped)


# Lấy tầm quan trọng của đặc trưng
feature_importances = model.feature_importances_

# In tầm quan trọng của đặc trưng
print(feature_importances)


feature_importances.shape


# Tạo dataframe gồm tên đặc trưng và tầm quan trọng
feature_importances_df = pd.DataFrame({"feature_name": feature_names, "importance": feature_importances})

# Sắp xếp dataframe theo tầm quan trọng
feature_importances_df = feature_importances_df.sort_values("importance", ascending=False)

# Lấy index của dataframe
indices = feature_importances_df.index

# In index
print(indices)


# Plot a horizontal bar chart of the feature importance scores
fig, ax = plt.subplots(figsize=(14, 22))  # Increase figure size for more space
y_pos = np.arange(len(feature_importances_df))
bar_height = 0.7  # Increase bar height for more space between bars
ax.barh(y_pos, feature_importances_df["importance"], align="center", color='skyblue', height=bar_height)
ax.set_yticks(y_pos)
ax.set_yticklabels(feature_importances_df["feature_name"], fontsize=10)  # Reduce font size if necessary
ax.invert_yaxis()  # Labels read top-to-bottom
ax.set_xlabel("Importance Score", fontsize=14)
ax.set_title("Feature Importance Scores (Random Forest)", fontsize=16)

# Add importance scores as labels on the horizontal bar chart
for i, v in enumerate(feature_importances_df["importance"]):
    ax.text(v + 0.01, i, str(round(v, 3)), color="black", fontweight="normal", fontsize=10, verticalalignment='center')  # Adjust position and alignment

plt.tight_layout(pad=2.0)  # Add padding for better layout
plt.show()


# Xác định số đặc trưng sẽ giữ lại để train  model
k = 64
top_k_indices = indices[:k]


# Giữ lại k đặc trưng tốt nhất trong tệp dữ liệu ban đầu
selected_X = X_train[:,:,top_k_indices]
selected_X_val = X_val[:,:,top_k_indices]
selected_X_test = X_test[:,:,top_k_indices]


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Khởi tạo mô hình
model = keras.Sequential()

# Thêm lớp Convolutional Layer với 32 bộ lọc kích thước 5x5 và hàm kích hoạt ReLU
model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(20, k, 1), padding='same'))

# Thêm lớp Convolutional Layer với 32 bộ lọc kích thước 5x5 và hàm kích hoạt ReLU
model.add(layers.Conv2D(32, (5,5), activation='relu', padding='same'))

# Thêm lớp Max Pooling 2D để giảm kích thước đầu vào đi 2 lần
model.add(layers.MaxPooling2D((2, 2)))

# Thêm lớp Dropout để giảm hiện tượng overfitting
model.add(layers.Dropout(0.5))

# Thêm lớp Convolutional Layer với 64 bộ lọc kích thước 3x3 và hàm kích hoạt ReLU
model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))

# Thêm lớp Convolutional Layer với 64 bộ lọc kích thước 3x3 và hàm kích hoạt ReLU
model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))

# Thêm lớp Max Pooling 2D để giảm kích thước đầu vào đi 2 lần
model.add(layers.MaxPooling2D((2, 2)))

# Thêm lớp Flatten để làm phẳng đầu ra của lớp trước khi đi vào các lớp fully connected
model.add(layers.Flatten())

# Thêm lớp fully connected (Dense Layer) với 64 units và hàm kích hoạt ReLU
model.add(layers.Dense(64, activation='relu'))

# Thêm lớp Dropout để giảm hiện tượng overfitting
model.add(layers.Dropout(0.5))

# Thêm lớp fully connected (Dense Layer) cuối cùng với số lớp đầu ra phụ thuộc vào bài toán của bạn
model.add(layers.Dense(5, activation='softmax'))

# In thông tin mô hình
model.summary()

# Biên dịch mô hình
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])



history_64 = model.fit(selected_X, y_train, epochs=10, batch_size=16, validation_data=(selected_X_val, y_val))


# Đánh giá mô hình trên tập kiểm tra
test_loss, test_accuracy = model.evaluate(selected_X_test, y_test)
print("Độ chính xác trên tập kiểm tra:", test_accuracy)

# Dự đoán các nhãn trên tập kiểm tra
y_pred = model.predict(selected_X_test)

# Chuyển đổi dự đoán thành nhãn dự đoán (lớp dự đoán)
y_pred_classes = np.argmax(y_pred, axis=1)

# Hiển thị ma trận nhầm lẫn
from sklearn.metrics import confusion_matrix, classification_report
confusion = confusion_matrix(y_test, y_pred_classes)
print("Ma trận nhầm lẫn:")
print(confusion)

# Hiển thị báo cáo phân loại
class_report = classification_report(y_test, y_pred_classes, digits=4)
print("Báo cáo phân loại:")
print(class_report)


# Kiểm tra xem có dữ liệu `val_loss` không
has_val_loss = 'val_loss' in history_64.history

# Vẽ biểu đồ loss cho k = 64
plt.figure(figsize=(10, 6))
plt.plot(history_64.history['loss'], label='Training Loss', color='blue')
if has_val_loss:
    plt.plot(history_64.history['val_loss'], label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Biểu Đồ Loss Với k = 64 Qua Các Epochs')
plt.legend(loc='upper right')  # Thêm chú thích
plt.grid(True)
plt.show()



import numpy as np
from sklearn.metrics import precision_recall_fscore_support

def micro_metrics(y_true, y_pred):
  # Calculate micro averages
  micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(
      y_true, y_pred.argmax(axis=1), average='micro'
  )
    
  # Macro averages
  macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(
      y_true, y_pred.argmax(axis=1), average='macro'
  )
  return {
      'micro_precision': micro_precision,
      'micro_recall': micro_recall,
      'micro_f1': micro_f1,
      'macro_precision': macro_precision,
      'macro_recall': macro_recall,
      'macro_f1': macro_f1
  }


from tabulate import tabulate
micro_results = micro_metrics(y_test, y_pred)
# Prepare table data
table_data = [
  ["Micro Precision", micro_results['micro_precision']],
  ["Micro Recall", micro_results['micro_recall']],
  ["Micro F1-score", micro_results['micro_f1']],
  ["Macro Precision", micro_results['macro_precision']],
  ["Macro Recall", micro_results['macro_recall']],
  ["Macro F1-score", micro_results['macro_f1']],
]

# Print the table using tabulate
print(tabulate(table_data, headers=["Metric", "Score"]))











import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support
from tabulate import tabulate
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import time

# Hàm để chạy mô hình với k đặc trưng
def run_model(k, X, X_test, y, y_test):
    # Chọn k đặc trưng tốt nhất
    top_k_indices = indices[:k]
    # Giữ lại k đặc trưng tốt nhất trong tệp dữ liệu ban đầu
    selected_X = X[:,:,top_k_indices]
    selected_X_test = X_test[:,:,top_k_indices]

    # Khởi tạo mô hình
    model = keras.Sequential()

    # Thêm các lớp của mô hình
    model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(20, k, 1), padding='same'))
    model.add(layers.Conv2D(32, (5, 5), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.5))
    model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))
    model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(5, activation='softmax'))

    # Biên dịch mô hình
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Bắt đầu đo thời gian huấn luyện
    start_time = time.time()

    # Huấn luyện mô hình
    history = model.fit(selected_X, y, epochs=10, batch_size=16, verbose=0)

    # Kết thúc đo thời gian huấn luyện
    end_time = time.time()
    training_time = end_time - start_time

    # Đánh giá mô hình trên tập kiểm tra
    test_loss, test_accuracy = model.evaluate(selected_X_test, y_test, verbose=0)
    print(f"Độ chính xác trên tập kiểm tra với {k} đặc trưng:", test_accuracy)

    # Dự đoán các nhãn trên tập kiểm tra
    y_pred = model.predict(selected_X_test)

    # Chuyển đổi dự đoán thành nhãn dự đoán
    y_pred_classes = np.argmax(y_pred, axis=1)

    # Hiển thị ma trận nhầm lẫn
    confusion = confusion_matrix(y_test, y_pred_classes)
    print("Ma trận nhầm lẫn:")
    print(confusion)

    # Hiển thị báo cáo phân loại
    class_report = classification_report(y_test, y_pred_classes, digits=4)
    print("Báo cáo phân loại:")
    print(class_report)

    # Tính toán micro và macro metrics
    micro_results = micro_metrics(y_test, y_pred)
    
    # Prepare table data
    table_data = [
      ["Micro Precision", micro_results['micro_precision']],
      ["Micro Recall", micro_results['micro_recall']],
      ["Micro F1-score", micro_results['micro_f1']],
      ["Macro Precision", micro_results['macro_precision']],
      ["Macro Recall", micro_results['macro_recall']],
      ["Macro F1-score", micro_results['macro_f1']],
    ]
    
    # Print the table using tabulate
    print(tabulate(table_data, headers=["Metric", "Score"]))

    # Trả về độ chính xác, kết quả micro metrics, ma trận nhầm lẫn, báo cáo phân loại, và thời gian huấn luyện
    return test_accuracy, micro_results, confusion, class_report, training_time, history

# Hàm tính toán micro và macro metrics
def micro_metrics(y_true, y_pred):
    # Calculate micro averages
    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(
        y_true, y_pred.argmax(axis=1), average='micro'
    )

    # Macro averages
    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(
        y_true, y_pred.argmax(axis=1), average='macro'
    )
    return {
        'micro_precision': micro_precision,
        'micro_recall': micro_recall,
        'micro_f1': micro_f1,
        'macro_precision': macro_precision,
        'macro_recall': macro_recall,
        'macro_f1': macro_f1
    }

# Các giá trị k cần thử nghiệm
k_values = [4, 8, 16, 32, 64, 96]

# Lưu trữ kết quả
results = []

# Thực hiện mô hình với từng giá trị k
for k in k_values:
    print(f"\nChạy mô hình với {k} đặc trưng...")
    accuracy, metrics, confusion, report, training_time, history = run_model(k, X, X_test, y, y_test)
    results.append((k, accuracy, metrics, confusion, report, training_time, history))

# So sánh kết quả và chọn k tối ưu
best_k_result = max(results, key=lambda x: x[1])
best_k = best_k_result[0]
print(f"\nGiá trị k tối ưu là: {best_k}")






# Tạo bảng kết quả
table_results = []

# Duyệt qua kết quả và chuẩn bị dữ liệu cho bảng
for k, accuracy, _, _, _, training_time, _ in results:
    table_results.append([k, accuracy, training_time])

# In bảng kết quả
headers = ["k", "Accuracy", "Training Time (s)"]
print("\nBảng Kết Quả:")
print(tabulate(table_results, headers=headers, tablefmt="pretty"))


# Lọc kết quả cho k = 16
k_64_result = next(result for result in results if result[0] == 64)

# Lấy đối tượng `history` từ kết quả cho k = 64
history_k_64 = k_64_result[-1]

# Kiểm tra xem có dữ liệu `val_loss` không
has_val_loss = 'val_loss' in history_k_64.history

# Vẽ biểu đồ loss cho k = 64
plt.figure(figsize=(10, 6))
plt.plot(history_k_64.history['loss'], label='Training Loss', color='blue')
if has_val_loss:
    plt.plot(history_k_64.history['val_loss'], label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Biểu Đồ Loss Với k = 64 Qua Các Epochs')
plt.legend(loc='upper right')  # Thêm chú thích
plt.grid(True)
plt.show()




