{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee258396-1d4e-4ef5-b2a5-3b5f668b3bc1",
   "metadata": {},
   "source": [
    "# Random forest importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830ed934-4284-4182-8cee-632a24ccd993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r X_256\n",
    "%store -r y_256\n",
    "%store -r X_test_256\n",
    "%store -r y_test_256\n",
    "%store -r feature_names_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510bd9da-a3a3-4ccd-9f79-fbb41f4d9a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import thư viện\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b73fd2c-feaa-46c0-af55-0dee95fb674e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape data\n",
    "# Data ban đầu X(13166, 20, 128), y(13166)\n",
    "\n",
    "# Reshape X về dạng 2d => X_2d(263320, 128), giữ nguyên 128 và đó là các đặc trưng\n",
    "X_2d = X_256.reshape(-1, X_256.shape[-1])\n",
    "# Reshape y thành y_reshaped(263320) bằng cách lặp mỗi phần tử trong y 20 lần\n",
    "y_reshaped = np.repeat(y_256, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1a0275-30e1-4cf8-9e0b-ffe81b73f8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Khởi tạo mô hình Random Forest\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "# Nó chỉ định số lượng cây quyết định sẽ được xây dựng và kết hợp để tạo thành khu rừng ngẫu nhiên trong thuật toán random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d77392-78a6-4340-b138-ed5669fd4125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình\n",
    "model.fit(X_2d, y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769031a-2762-4a93-800f-46a1bddaf40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lấy tầm quan trọng của đặc trưng\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# In tầm quan trọng của đặc trưng\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85046b-8cde-4f61-bc14-a8a23e3a43b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3c329-0c62-4144-8f18-4cc42b33a29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b61bcd-3b32-4ed2-b69e-9bb4d54f445b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo dataframe gồm tên đặc trưng và tầm quan trọng\n",
    "feature_importances_df = pd.DataFrame({\"feature_name\": feature_names_256, \"importance\": feature_importances})\n",
    "\n",
    "# Sắp xếp dataframe theo tầm quan trọng\n",
    "feature_importances_df = feature_importances_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Lấy index của dataframe\n",
    "indices = feature_importances_df.index\n",
    "\n",
    "# In index\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f548b-fccc-4db8-bd92-b9d6d3363a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xác định số đặc trưng sẽ giữ lại để train  model\n",
    "k = 128\n",
    "top_k_indices = indices[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216f5a0-f86e-40e7-b199-63521ea65e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Giữ lại k đặc trưng tốt nhất trong tệp dữ liệu ban đầu\n",
    "selected_X = X_256[:,:,top_k_indices]\n",
    "selected_X_test = X_test_256[:,:,top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff299b-df42-4539-ba0d-da1ce0da3722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Input(shape = (20, k, 1)))\n",
    "\n",
    "# Thêm lớp Convolutional Layer với 32 bộ lọc kích thước 5x5 và hàm kích hoạt ReLU\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "\n",
    "# Thêm lớp Convolutional Layer với 32 bộ lọc kích thước 5x5 và hàm kích hoạt ReLU\n",
    "model.add(layers.Conv2D(32, (5,5), activation='relu', padding='same'))\n",
    "\n",
    "# Thêm lớp Max Pooling 2D để giảm kích thước đầu vào đi 2 lần\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Thêm lớp Dropout để giảm hiện tượng overfitting\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Thêm lớp Convolutional Layer với 64 bộ lọc kích thước 3x3 và hàm kích hoạt ReLU\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "\n",
    "# Thêm lớp Convolutional Layer với 64 bộ lọc kích thước 3x3 và hàm kích hoạt ReLU\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "\n",
    "# Thêm lớp Max Pooling 2D để giảm kích thước đầu vào đi 2 lần\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Thêm lớp Flatten để làm phẳng đầu ra của lớp trước khi đi vào các lớp fully connected\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Thêm lớp fully connected (Dense Layer) với 64 units và hàm kích hoạt ReLU\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Thêm lớp Dropout để giảm hiện tượng overfitting\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Thêm lớp fully connected (Dense Layer) cuối cùng với số lớp đầu ra phụ thuộc vào bài toán của bạn\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# In thông tin mô hình\n",
    "model.summary()\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609e462-3411-4e0a-8a86-50a10635e6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(selected_X, y_256, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a32a76-2b14-4017-8405-66d10ecd2cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss, test_accuracy = model.evaluate(selected_X_test, y_test_256)\n",
    "print(\"Độ chính xác trên tập kiểm tra:\", test_accuracy)\n",
    "\n",
    "# Dự đoán các nhãn trên tập kiểm tra\n",
    "y_pred = model.predict(selected_X_test)\n",
    "\n",
    "# Chuyển đổi dự đoán thành nhãn dự đoán (lớp dự đoán)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Hiển thị ma trận nhầm lẫn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "confusion = confusion_matrix(y_test_256, y_pred_classes)\n",
    "print(\"Ma trận nhầm lẫn:\")\n",
    "print(confusion)\n",
    "\n",
    "# Hiển thị báo cáo phân loại\n",
    "class_report = classification_report(y_test_256, y_pred_classes)\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b84b1-3e46-4281-84f2-1dcdb8bbd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def micro_metrics(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates micro and macro average precision, recall, and F1-score for multi-class classification.\n",
    "\n",
    "  Args:\n",
    "      y_true: List of true labels (length should match the number of data points in y_pred).\n",
    "      y_pred: Predicted class probabilities for each data point (shape: (num_data, num_classes)).\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing micro and macro average precision, recall, and F1-score.\n",
    "  \"\"\"\n",
    "\n",
    "  # Ensure y_true and y_pred have compatible shapes\n",
    "  if len(y_true) != y_pred.shape[0]:\n",
    "    raise ValueError(\"y_true and y_pred must have the same number of data points.\")\n",
    "\n",
    "  # Count true positives (TP), false positives (FP), false negatives (FN) per class\n",
    "  # Assuming y_pred contains class probabilities\n",
    "  y_pred_argmax = np.argmax(y_pred, axis=1)  # Get the predicted class index\n",
    "  n_classes = y_pred.shape[1]  # Number of classes\n",
    "\n",
    "  class_tp = np.zeros(n_classes)\n",
    "  class_fp = np.zeros(n_classes)\n",
    "  class_fn = np.zeros(n_classes)\n",
    "  for y_t, y_p in zip(y_true, y_pred_argmax):\n",
    "    class_tp[y_t] += 1\n",
    "    if y_p != y_t:\n",
    "      class_fp[y_p] += 1\n",
    "      class_fn[y_t] += 1\n",
    "\n",
    "  # Calculate micro and macro averages\n",
    "  # Micro averages (already calculated in previous version)\n",
    "  micro_tp = np.sum(class_tp)\n",
    "  micro_fp = np.sum(class_fp)\n",
    "  micro_fn = np.sum(class_fn)\n",
    "  micro_precision = micro_tp / (micro_tp + micro_fp) if (micro_tp + micro_fp) > 0 else 0\n",
    "  micro_recall = micro_tp / (micro_tp + micro_fn) if (micro_tp + micro_fn) > 0 else 0\n",
    "  micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0\n",
    "\n",
    "  # Macro averages\n",
    "  macro_precision = np.mean([p / (p + fp) for p, fp in zip(class_tp, class_fp) if (p + fp) > 0])\n",
    "  macro_recall = np.mean([r / (r + fn) for r, fn in zip(class_tp, class_fn) if (r + fn) > 0])\n",
    "  macro_f1 = 2 * (macro_precision * macro_recall) / (macro_precision + macro_recall) if (macro_precision + macro_recall) > 0 else 0\n",
    "\n",
    "  return {\n",
    "      'micro_precision': micro_precision,\n",
    "      'micro_recall': micro_recall,\n",
    "      'micro_f1': micro_f1,\n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'macro_f1': macro_f1\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99e73e-4555-4487-9dd9-f470e9331b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate micro metrics\n",
    "micro_results = micro_metrics(y_test_256, y_pred)\n",
    "\n",
    "print(\"Micro Precision:\", micro_results['micro_precision'])\n",
    "print(\"Micro Recall:\", micro_results['micro_recall'])\n",
    "print(\"Micro F1-score:\", micro_results['micro_f1'])\n",
    "\n",
    "print(\"Macro Precision:\", micro_results['macro_precision'])\n",
    "print(\"Macro Recall:\", micro_results['macro_recall'])\n",
    "print(\"Macro F1-score:\", micro_results['macro_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ce7d6-8c24-4018-8c0e-2cde035044c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "  [\"Micro Precision\", micro_results['micro_precision']],\n",
    "  [\"Micro Recall\", micro_results['micro_recall']],\n",
    "  [\"Micro F1-score\", micro_results['micro_f1']],\n",
    "  [\"Macro Precision\", micro_results['macro_precision']],\n",
    "  [\"Macro Recall\", micro_results['macro_recall']],\n",
    "  [\"Macro F1-score\", micro_results['macro_f1']],\n",
    "]\n",
    "\n",
    "# Print the table using tabulate\n",
    "print(tabulate(table_data, headers=[\"Metric\", \"Score\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
